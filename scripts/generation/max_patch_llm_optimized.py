#!/usr/bin/env python3
"""
æœ€é©åŒ–ã•ã‚ŒãŸMax/MSP LLMã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆé«˜é€Ÿç‰ˆï¼‰
"""

import os
import json
import re
from llama_cpp import Llama

class OptimizedMaxPatchLLM:
    def __init__(self):
        # å‹•ä½œç¢ºèªæ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        self.model_path = "/Users/mymac/manxo/models/llm/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf"
        self.model = None
        
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.model_path}")
    
    def load_model_optimized(self):
        """æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã§ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰"""
        if self.model is None:
            print(f"ğŸš€ æœ€é©åŒ–è¨­å®šã§LLMãƒ­ãƒ¼ãƒ‰ä¸­...")
            
            self.model = Llama(
                model_path=self.model_path,
                
                # ğŸ”§ é«˜é€ŸåŒ–è¨­å®š
                n_ctx=512,          # â† å°ã•ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆé«˜é€Ÿï¼‰
                n_batch=8,          # â† å°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚º
                n_threads=4,        # â† ã‚¹ãƒ¬ãƒƒãƒ‰æ•°æŒ‡å®š
                n_gpu_layers=0,     # â† ã¨ã‚Šã‚ãˆãšCPUï¼ˆå®‰å®šæ€§å„ªå…ˆï¼‰
                
                # ğŸ“ˆ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
                use_mmap=True,      # â† ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ”ãƒ³ã‚°æœ‰åŠ¹
                use_mlock=False,    # â† ãƒ¡ãƒ¢ãƒªãƒ­ãƒƒã‚¯ç„¡åŠ¹ï¼ˆæŸ”è»Ÿæ€§å„ªå…ˆï¼‰
                
                # ğŸ”‡ ãƒ­ã‚°è¨­å®š
                verbose=False,
                
                # âš¡ è¿½åŠ æœ€é©åŒ–
                f16_kv=True,        # â† KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’FP16ã§ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
                logits_all=False,   # â† å…¨ãƒ­ã‚¸ãƒƒãƒˆä¸è¦ï¼ˆé«˜é€ŸåŒ–ï¼‰
            )
            print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
    
    def generate_fast(self, prompt, max_tokens=150):
        """é«˜é€Ÿç”Ÿæˆï¼ˆæœ€å°è¨­å®šï¼‰"""
        self.load_model_optimized()
        
        print(f"ğŸ’¬ é«˜é€Ÿç”Ÿæˆé–‹å§‹...")
        start_time = __import__('time').time()
        
        try:
            response = self.model(
                prompt,
                max_tokens=max_tokens,
                
                # ğŸš€ é«˜é€ŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
                temperature=0.1,    # â† ä½æ¸©åº¦ï¼ˆæ±ºå®šçš„ï¼‰
                top_p=0.9,         # â† nucleus sampling
                repeat_penalty=1.1, # â† ç¹°ã‚Šè¿”ã—é˜²æ­¢
                
                # â¹ï¸ åœæ­¢æ¡ä»¶
                stop=["\\n\\n", "```", "Response:", "Human:"],
                
                # ğŸ”‡ ã‚¨ã‚³ãƒ¼ç„¡åŠ¹
                echo=False,
                
                # âš¡ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç„¡åŠ¹ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
                stream=False
            )
            
            duration = __import__('time').time() - start_time
            print(f"â±ï¸ ç”Ÿæˆæ™‚é–“: {duration:.1f}ç§’")
            
            return response['choices'][0]['text'].strip()
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def parse_intent_fast(self, user_input):
        """é«˜é€Ÿæ„å›³è§£æ"""
        
        # ğŸ“ çŸ­ç¸®ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆé«˜é€ŸåŒ–ï¼‰
        prompt = f"""Max/MSP expert. JSON only.

Request: "{user_input}"

JSON:
{{
  "category": "effect|synth|utility",
  "objects": ["obj1", "obj2"],
  "params": {{"key": "value"}}
}}"""
        
        print(f"ğŸ§  æ„å›³è§£æ: {user_input}")
        
        result_text = self.generate_fast(prompt, max_tokens=100)
        
        if result_text:
            print(f"ğŸ¤– LLMå¿œç­”: {result_text}")
            
            # JSONæŠ½å‡º
            json_data = self._extract_json_fast(result_text)
            if json_data:
                return json_data
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        print("âš ï¸ LLMè§£æå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
        return self._fallback_parse(user_input)
    
    def _extract_json_fast(self, text):
        """é«˜é€ŸJSONæŠ½å‡º"""
        try:
            # æœ€åˆã®JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ã™
            start = text.find('{')
            if start == -1:
                return None
                
            # å¯¾å¿œã™ã‚‹}ã‚’æ¢ã™
            brace_count = 0
            end = start
            for i, char in enumerate(text[start:], start):
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        end = i + 1
                        break
            
            if brace_count == 0:
                json_str = text[start:end]
                return json.loads(json_str)
                
        except Exception as e:
            print(f"JSONæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return None
    
    def _fallback_parse(self, user_input):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£æï¼ˆé«˜é€Ÿãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰"""
        
        user_lower = user_input.lower()
        
        # ğŸ¯ ã‚·ãƒ³ãƒ—ãƒ«ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        if any(word in user_lower for word in ['reverb', 'ãƒªãƒãƒ¼ãƒ–']):
            return {
                'category': 'effect',
                'objects': ['adc~', 'freeverb~', 'dac~'],
                'params': {'roomsize': '0.8'}
            }
        elif any(word in user_lower for word in ['delay', 'ãƒ‡ã‚£ãƒ¬ã‚¤']):
            return {
                'category': 'effect', 
                'objects': ['adc~', 'tapin~', 'tapout~', 'dac~'],
                'params': {'time': '500'}
            }
        elif any(word in user_lower for word in ['filter', 'ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼']):
            return {
                'category': 'effect',
                'objects': ['adc~', 'lores~', 'dac~'],
                'params': {'freq': '1000'}
            }
        elif any(word in user_lower for word in ['osc', 'oscillator', 'ã‚ªã‚·ãƒ¬ãƒ¼ã‚¿ãƒ¼']):
            return {
                'category': 'synth',
                'objects': ['phasor~', 'dac~'],
                'params': {'freq': '440'}
            }
        elif any(word in user_lower for word in ['fm', 'bell', 'ãƒ™ãƒ«']):
            return {
                'category': 'synth',
                'objects': ['phasor~', '*~', '+~', 'cos~', 'dac~'],
                'params': {'carrier': '440', 'mod': '220'}
            }
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        return {
            'category': 'utility',
            'objects': ['adc~', 'dac~'],
            'params': {}
        }
    
    def unload_model(self):
        """ãƒ¡ãƒ¢ãƒªè§£æ”¾"""
        if self.model:
            del self.model
            self.model = None
            import gc
            gc.collect()
            print("ğŸ—‘ï¸ ãƒ¢ãƒ‡ãƒ«è§£æ”¾å®Œäº†")

def speed_test():
    """é€Ÿåº¦ãƒ†ã‚¹ãƒˆ"""
    
    llm = OptimizedMaxPatchLLM()
    
    test_cases = [
        "ãƒªãƒãƒ¼ãƒ–ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ",
        "FM synthesis bell",
        "lowpass filter", 
        "delay effect"
    ]
    
    print("âš¡ é«˜é€ŸåŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹\\n")
    
    total_time = __import__('time').time()
    
    for i, test_input in enumerate(test_cases, 1):
        print(f"=== ãƒ†ã‚¹ãƒˆ {i}/{len(test_cases)} ===")
        
        start = __import__('time').time()
        result = llm.parse_intent_fast(test_input)
        duration = __import__('time').time() - start
        
        print(f"ğŸ“Š çµæœ: {result}")
        print(f"â±ï¸ å‡¦ç†æ™‚é–“: {duration:.1f}ç§’\\n")
    
    total_duration = __import__('time').time() - total_time
    print(f"ğŸ ç·æ™‚é–“: {total_duration:.1f}ç§’")
    print(f"ğŸ“ˆ å¹³å‡: {total_duration/len(test_cases):.1f}ç§’/ãƒ†ã‚¹ãƒˆ")
    
    llm.unload_model()

if __name__ == "__main__":
    speed_test()