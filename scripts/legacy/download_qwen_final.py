#!/usr/bin/env python3
"""
æ­£ç¢ºãªãƒ•ã‚¡ã‚¤ãƒ«åã§Qwenãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
"""

from huggingface_hub import hf_hub_download, list_repo_files
import os
import subprocess

def download_qwen_with_cli():
    """huggingface-cliã‚’ä½¿ã£ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    
    model_dir = "/Users/mymac/manxo/models/llm"
    os.makedirs(model_dir, exist_ok=True)
    
    try:
        print("ğŸš€ huggingface-cliã§Qwen2.5-7B Q4ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        # huggingface-cliã‚’ä½¿ç”¨
        cmd = [
            "huggingface-cli", "download", 
            "Qwen/Qwen2.5-7B-Instruct-GGUF",
            "--include", "*q4_k_m*.gguf",
            "--local-dir", model_dir
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)
        
        if result.returncode == 0:
            print("âœ… huggingface-cliãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ!")
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
            gguf_files = [f for f in os.listdir(model_dir) if f.endswith('.gguf')]
            if gguf_files:
                model_path = os.path.join(model_dir, gguf_files[0])
                file_size = os.path.getsize(model_path) / (1024**3)
                print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {gguf_files[0]} ({file_size:.1f}GB)")
                return model_path
        else:
            print(f"âŒ huggingface-cliå¤±æ•—: {result.stderr}")
            
    except Exception as e:
        print(f"âŒ huggingface-cli ã‚¨ãƒ©ãƒ¼: {e}")
    
    return None

def download_qwen_python_api():
    """Python APIã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    
    model_dir = "/Users/mymac/manxo/models/llm"
    
    try:
        print("ğŸ”„ Python APIã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
        files = list_repo_files("Qwen/Qwen2.5-7B-Instruct-GGUF")
        q4_files = [f for f in files if 'q4_k_m' in f and f.endswith('.gguf')]
        
        print(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªQ4ãƒ•ã‚¡ã‚¤ãƒ«: {q4_files}")
        
        if q4_files:
            target_file = q4_files[0]  # æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
            print(f"â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {target_file}")
            
            model_path = hf_hub_download(
                repo_id="Qwen/Qwen2.5-7B-Instruct-GGUF",
                filename=target_file,
                local_dir=model_dir
            )
            
            file_size = os.path.getsize(model_path) / (1024**3)
            print(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {file_size:.1f}GB")
            return model_path
            
    except Exception as e:
        print(f"âŒ Python API ã‚¨ãƒ©ãƒ¼: {e}")
    
    return None

def download_bartowski_alternative():
    """bartowskiã®ä»£æ›¿ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    
    model_dir = "/Users/mymac/manxo/models/llm"
    
    try:
        print("ğŸ”„ Bartowskiç‰ˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        model_path = hf_hub_download(
            repo_id="bartowski/Qwen2.5-7B-Instruct-GGUF",
            filename="Qwen2.5-7B-Instruct-Q4_K_M.gguf",
            local_dir=model_dir
        )
        
        file_size = os.path.getsize(model_path) / (1024**3)
        print(f"âœ… Bartowskiç‰ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {file_size:.1f}GB")
        return model_path
        
    except Exception as e:
        print(f"âŒ Bartowskiç‰ˆã‚¨ãƒ©ãƒ¼: {e}")
    
    return None

def test_downloaded_model(model_path):
    """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    if not model_path or not os.path.exists(model_path):
        return False
    
    try:
        from llama_cpp import Llama
        
        print(f"ğŸ§  ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ: {os.path.basename(model_path)}")
        model = Llama(
            model_path=model_path,
            n_ctx=512,
            n_gpu_layers=0,
            verbose=False
        )
        
        # Max/MSPç‰¹åŒ–ãƒ†ã‚¹ãƒˆ
        response = model(
            "Max/MSPã§ãƒªãƒãƒ¼ãƒ–ã‚’ä½œã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ï¼Ÿ",
            max_tokens=30,
            echo=False
        )
        
        print("âœ… ãƒ¢ãƒ‡ãƒ«å‹•ä½œç¢ºèª!")
        print(f"ğŸ“ å¿œç­”ä¾‹: {response['choices'][0]['text'][:100]}")
        
        del model
        import gc
        gc.collect()
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ Qwen2.5-7B Q4é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹...")
    
    model_path = None
    
    # æ–¹æ³•1: huggingface-cli
    model_path = download_qwen_with_cli()
    
    # æ–¹æ³•2: Python APIï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    if not model_path:
        model_path = download_qwen_python_api()
    
    # æ–¹æ³•3: Bartowskiç‰ˆï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰
    if not model_path:
        model_path = download_bartowski_alternative()
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    if model_path and test_downloaded_model(model_path):
        print("\nğŸ‰ Qwen2.5-7B ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†!")
        print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {model_path}")
        print("ğŸ”§ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ãƒ‘ãƒƒãƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆ")
    else:
        print("\nâŒ å…¨ã¦ã®æ–¹æ³•ãŒå¤±æ•—ã—ã¾ã—ãŸ")
        print("ğŸ’¡ æ¨å¥¨: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã¨HuggingFaceã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„")