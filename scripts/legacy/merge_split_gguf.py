#!/usr/bin/env python3
"""
åˆ†å‰²ã•ã‚ŒãŸGGUFãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
"""

import os
import glob

def merge_split_gguf():
    """åˆ†å‰²ã•ã‚ŒãŸGGUFãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ"""
    
    model_dir = "/Users/mymac/manxo/models/llm"
    
    # åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    pattern = os.path.join(model_dir, "qwen2.5-7b-instruct-q4_k_m-*-of-*.gguf")
    split_files = sorted(glob.glob(pattern))
    
    print(f"ğŸ“ åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {len(split_files)}å€‹")
    for f in split_files:
        size_gb = os.path.getsize(f) / (1024**3)
        print(f"  - {os.path.basename(f)}: {size_gb:.1f}GB")
    
    if len(split_files) < 2:
        print("âŒ åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸å®Œå…¨ã§ã™")
        return None
    
    # çµåˆå¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«å
    merged_file = os.path.join(model_dir, "qwen2.5-7b-instruct-q4_k_m.gguf")
    
    print(f"ğŸ”— ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆä¸­: {os.path.basename(merged_file)}")
    
    try:
        with open(merged_file, 'wb') as outfile:
            for split_file in split_files:
                print(f"  ğŸ“¥ è¿½åŠ ä¸­: {os.path.basename(split_file)}")
                with open(split_file, 'rb') as infile:
                    # 64MBãšã¤èª­ã¿è¾¼ã‚“ã§çµåˆ
                    while True:
                        chunk = infile.read(64 * 1024 * 1024)
                        if not chunk:
                            break
                        outfile.write(chunk)
        
        # çµåˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºç¢ºèª
        merged_size = os.path.getsize(merged_file) / (1024**3)
        print(f"âœ… çµåˆå®Œäº†: {merged_size:.1f}GB")
        
        return merged_file
        
    except Exception as e:
        print(f"âŒ çµåˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def test_merged_model(model_path):
    """çµåˆã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    if not model_path or not os.path.exists(model_path):
        return False
    
    try:
        from llama_cpp import Llama
        
        print(f"ğŸ§  çµåˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ: {os.path.basename(model_path)}")
        
        model = Llama(
            model_path=model_path,
            n_ctx=1024,
            n_gpu_layers=0,
            verbose=False
        )
        
        print("ğŸ’¬ Max/MSPç‰¹åŒ–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        test_prompt = """ã‚ãªãŸã¯Max/MSPã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è¦æ±‚ã‚’åˆ†æã—ã¦JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

è¦æ±‚: "ã‚¹ãƒ†ãƒ¬ã‚ªãƒªãƒãƒ¼ãƒ–ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’ä½œã£ã¦"

JSONå½¢å¼ã§å›ç­”:
{
  "category": "effect",
  "subcategory": "reverb",
  "objects": ["adc~", "freeverb~", "dac~"],
  "parameters": {"roomsize": 0.8},
  "complexity": 2
}

è¦æ±‚: "ãƒ‡ã‚£ã‚¹ãƒˆãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’ä½œã£ã¦"

JSON:"""
        
        response = model(
            test_prompt,
            max_tokens=150,
            stop=["\n\n"],
            echo=False,
            temperature=0.1
        )
        
        result = response['choices'][0]['text']
        print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆæˆåŠŸ!")
        print(f"ğŸ“ JSONå¿œç­”:")
        print(result)
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del model
        import gc
        gc.collect()
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False

def cleanup_split_files():
    """åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"""
    
    model_dir = "/Users/mymac/manxo/models/llm"
    pattern = os.path.join(model_dir, "qwen2.5-7b-instruct-q4_k_m-*-of-*.gguf")
    split_files = glob.glob(pattern)
    
    print(f"ğŸ—‘ï¸ åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«{len(split_files)}å€‹ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ (y/N): ", end="")
    response = input().lower()
    
    if response == 'y':
        for f in split_files:
            os.remove(f)
            print(f"  ğŸ—‘ï¸ å‰Šé™¤: {os.path.basename(f)}")
        print("âœ… åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†")
    else:
        print("â¸ï¸ åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¿æŒã•ã‚Œã¾ã™")

if __name__ == "__main__":
    print("ğŸ”— åˆ†å‰²GGUFãƒ•ã‚¡ã‚¤ãƒ«ã®çµåˆé–‹å§‹...")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
    merged_file = merge_split_gguf()
    
    if merged_file:
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        if test_merged_model(merged_file):
            print("\nğŸ‰ Qwen2.5-7B çµåˆãƒ»ãƒ†ã‚¹ãƒˆå®Œäº†!")
            print(f"ğŸ“ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: {merged_file}")
            
            # åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            cleanup_split_files()
            
        else:
            print("\nâš ï¸ çµåˆæˆåŠŸã€ãƒ†ã‚¹ãƒˆå¤±æ•—")
    else:
        print("\nâŒ ãƒ•ã‚¡ã‚¤ãƒ«çµåˆå¤±æ•—")