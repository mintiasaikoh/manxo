#!/usr/bin/env python3
"""
æ­£ã—ã„Qwenãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
"""

from huggingface_hub import hf_hub_download
import os

def download_qwen_q4():
    """Qwen 7B Q4é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    
    model_dir = "/Users/mymac/manxo/models/llm"
    os.makedirs(model_dir, exist_ok=True)
    
    print("ğŸš€ Qwen2.5-7B Q4é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    print("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: ç´„4.4GB")
    
    try:
        model_path = hf_hub_download(
            repo_id="Qwen/Qwen2.5-7B-Instruct-GGUF",
            filename="qwen2.5-7b-instruct-q4_k_m.gguf",
            local_dir=model_dir
        )
        
        print(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {model_path}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        file_size = os.path.getsize(model_path) / (1024**3)
        print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} GB")
        
        return model_path
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def test_qwen_model(model_path):
    """Qwenãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ"""
    if not model_path or not os.path.exists(model_path):
        return False
    
    try:
        from llama_cpp import Llama
        
        print("ğŸ§  Qwenãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        model = Llama(
            model_path=model_path,
            n_ctx=1024,
            n_gpu_layers=0,
            verbose=False
        )
        
        print("ğŸ’¬ Max/MSPç‰¹åŒ–ãƒ†ã‚¹ãƒˆä¸­...")
        
        # Max/MSPç‰¹åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompt = """ã‚ãªãŸã¯Max/MSPã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è¦æ±‚ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

è¦æ±‚: "ã‚¹ãƒ†ãƒ¬ã‚ªãƒªãƒãƒ¼ãƒ–ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’ä½œã£ã¦"

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{
  "category": "effect",
  "subcategory": "reverb", 
  "objects": ["adc~", "freeverb~", "dac~"],
  "parameters": {"roomsize": 0.8, "damp": 0.5},
  "complexity": 2
}"""
        
        response = model(
            prompt,
            max_tokens=200,
            stop=["}"],
            echo=False,
            temperature=0.1
        )
        
        result = response['choices'][0]['text'] + "}"
        print("âœ… Qwenãƒ†ã‚¹ãƒˆæˆåŠŸ!")
        print(f"ğŸ“ JSONå¿œç­”: {result}")
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del model
        import gc
        gc.collect()
        
        return True
        
    except Exception as e:
        print(f"âŒ Qwenãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    # Qwen 7B Q4ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    model_path = download_qwen_q4()
    
    if model_path:
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        if test_qwen_model(model_path):
            print("\nğŸ‰ Qwen2.5-7B ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†!")
            print("Max/MSPãƒ‘ãƒƒãƒç”Ÿæˆã®æº–å‚™ãŒã§ãã¾ã—ãŸã€‚")
        else:
            print("\nâš ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸã€ãƒ†ã‚¹ãƒˆå¤±æ•—")
    else:
        print("\nâŒ Qwenãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—")